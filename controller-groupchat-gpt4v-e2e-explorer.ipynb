{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c75da30",
   "metadata": {},
   "source": [
    "# Agent Chat with Multimodal Models: GPT-4V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f51914c",
   "metadata": {},
   "source": [
    "### Before everything starts, install AutoGen with the `lmm` option\n",
    "```bash\n",
    "pip install \"pyautogen[lmm]~=0.2.0b4\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67d45964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "\n",
    "import autogen\n",
    "from autogen import AssistantAgent, Agent, UserProxyAgent, ConversableAgent\n",
    "from termcolor import colored\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d5580e",
   "metadata": {},
   "source": [
    "Within the user proxy agent, we can decide to activate the human input mode or not (for here, we use human_input_mode=\"NEVER\" for conciseness). This allows you to interact with LMM in a multi-round dialogue, enabling you to provide feedback as the conversation unfolds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1db6f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.agentchat.contrib.multimodal_conversable_agent import MultimodalConversableAgent\n",
    "\n",
    "config_list_4v = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4-vision-preview\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "config_list_gpt4 = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4\", \"gpt-4-0314\", \"gpt4\", \"gpt-4-32k\", \"gpt-4-32k-0314\", \"gpt-4-32k-v0314\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "gpt4_llm_config = {\"config_list\": config_list_gpt4, \"cache_seed\": 42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ece3be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57462351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the `api_type` param as it is not needed for 4V\n",
    "[config.pop(\"api_type\", None) for config in config_list_4v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05a60de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f36f96db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import workspaceId, token, extract_element_bbox, \\\n",
    "                request_image_annotation, draw_bboxes, encode_image, send_to_gpt, \\\n",
    "                extract_numbers\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a96786d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0fbc4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "class Controller:\n",
    "    def __init__(self, window_name=\"Mozilla Firefox\") -> None:    \n",
    "        # Get the window ID (replace 'Window_Name' with your window's title)\n",
    "        self.window_name = window_name\n",
    "        self.get_window_id = [\"xdotool\", \"search\", \"--name\", self.window_name]\n",
    "        self.window_id = subprocess.check_output(self.get_window_id).strip()\n",
    "\n",
    "    def move_mouse(self, x, y, click=1):\n",
    "        # AI logic to determine the action (not shown)\n",
    "        action = {\"x\": x, \"y\": y, \"click\": click}\n",
    "        # Move the mouse and click within the window\n",
    "        if action[\"click\"]:\n",
    "            subprocess.run([\"xdotool\", \"mousemove\", \"--window\", self.window_id, str(action[\"x\"]), str(action[\"y\"])])\n",
    "            subprocess.run([\"xdotool\", \"click\", \"--window\", self.window_id, \"1\"])\n",
    "\n",
    "        # Print AI decisions in terminal\n",
    "        print(f\"Moved to {action['x']}, {action['y']} and clicked: {action['click']}\")\n",
    "        # wait before next action\n",
    "        time.sleep(2)\n",
    "\n",
    "    def double_click_at_location(self, x, y):\n",
    "        # Move the mouse to the specified location\n",
    "        subprocess.run([\"xdotool\", \"mousemove\", \"--window\", self.window_id, str(int(x)), str(int(y))])\n",
    "        # Double click\n",
    "        subprocess.run([\"xdotool\", \"click\", \"--repeat\", \"1\", \"--window\", self.window_id, \"1\"])\n",
    "        time.sleep(0.1)\n",
    "        subprocess.run([\"xdotool\", \"click\", \"--repeat\", \"1\", \"--window\", self.window_id, \"1\"])\n",
    "\n",
    "    def enter_text_at_location(self, text, x, y):\n",
    "        # Move the mouse to the specified location\n",
    "        subprocess.run([\"xdotool\", \"mousemove\", \"--window\", self.window_id, str(int(x)), str(int(y))])\n",
    "        # Click to focus at the location\n",
    "        subprocess.run([\"xdotool\", \"click\", \"--window\", self.window_id, \"1\"])\n",
    "        # Type the text\n",
    "        subprocess.run([\"xdotool\", \"type\", \"--window\", self.window_id, text])\n",
    "\n",
    "    def press_enter(self):\n",
    "        subprocess.run([\"xdotool\", \"key\", \"--window\", self.window_id, \"Return\"])\n",
    "\n",
    "    def take_screenshot(self):\n",
    "        # Take a screenshot\n",
    "        print(\"Taking screenshot....\")\n",
    "        screenshot_command = [\"import\", \"-window\", self.window_id, \"screenshot.png\"]\n",
    "        subprocess.run(screenshot_command)\n",
    "        # Wait before next action\n",
    "        time.sleep(1)\n",
    "        self.image = Image.open(\"screenshot.png\").convert(\"RGB\")\n",
    "        self.aui_annotate()\n",
    "        return \"screenshot taken with UI elements numbered at screenshot_annotated.png \"\n",
    "\n",
    "    def aui_annotate(self):\n",
    "        print(f\"aui_annotate function is called...\")\n",
    "        assert os.path.exists(\"screenshot.png\"), \"Screenshot not taken\"\n",
    "        self.raw_data = (request_image_annotation(\"screenshot.png\", workspaceId, token)).json()\n",
    "        self.image_with_bboxes = draw_bboxes(self.image, self.raw_data)\n",
    "        self.image_with_bboxes.save(\"screenshot_annotated.png\")\n",
    "    \n",
    "    def extract_location_from_index(self, index):\n",
    "        print(f\"Extract location function is called...\")\n",
    "        bbox = extract_element_bbox([index], self.raw_data)\n",
    "        return [(bbox[0]+bbox[2])/2, (bbox[1]+bbox[3])/2]\n",
    "    \n",
    "    def convert_image_to_base64(self):\n",
    "        return encode_image(\"screenshot_annotated.png\")\n",
    "    \n",
    "    def get_target_UIelement_number(self, query):\n",
    "        base64_image = self.convert_image_to_base64()\n",
    "        gpt_response = send_to_gpt(base64_image, query)\n",
    "        gpt_response = gpt_response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        print(f\"GPT resposne is {gpt_response}\")\n",
    "        # Extract numbers from the GPT response\n",
    "        numbers = extract_numbers(gpt_response)\n",
    "        return numbers[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4036f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"take_screenshot\",\n",
    "            \"description\": \"take screenshot of the UI window. Annotate UI elements - Draw bounding boxes of the UI elements with numbers on the image and save under screenshot_annotated.png\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {},\n",
    "                \"required\": [],\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"move_mouse\",\n",
    "            \"description\": \"move the mouse to a position (x,y) in the UI window\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"x\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"x coordinate of the x,y point\",\n",
    "                    },\n",
    "                    \"y\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"y coordinate of the x,y point\",\n",
    "                    },\n",
    "                    \"click\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"Bool flag to know whether to make the left click action after moving to x,y\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"x\", \"y\", \"click\"],\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"double_click_at_location\",\n",
    "            \"description\": \"Double click on a location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"x\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"x coordinate of the x,y point\",\n",
    "                    },\n",
    "                    \"y\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"y coordinate of the x,y point\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"x\", \"y\"],\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"extract_location_from_index\",\n",
    "            \"description\": \"Extract the position (x,y) from the index/number of the UI element detected\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"index\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"number of the UI element\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"index\"],\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"get_target_UIelement_number\",\n",
    "            \"description\": \"Given an annotated image and query about specific UI element, get the index/number of the desired element from an advanced model\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Query considering the UI element to click on\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"enter_text_at_location\",\n",
    "            \"description\": \"Enter text at a specified location in the UI window\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"text\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Text to enter\",\n",
    "                    },\n",
    "                    \"x\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"x coordinate of the x,y point\",\n",
    "                    },\n",
    "                    \"y\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"y coordinate of the x,y point\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"x\", \"y\", \"text\"],\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"press_enter\",\n",
    "            \"description\": \"Press enter key\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {},\n",
    "                \"required\": [],\n",
    "            },\n",
    "        }\n",
    "\n",
    "    ],\n",
    "    \"config_list\": config_list_gpt4,\n",
    "#     \"temperature\": 0.4,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "planner = autogen.AssistantAgent(\n",
    "    name=\"Planner\",\n",
    "    system_message=\"\"\"You are the orchestrator that must achieve the given task. You are given functions to handle the UI window. Remember that you are given a UI window and you start the task by taking a screenshot and take screenshot after each action. For coding tasks, only use the functions you have been provided with. Reply TERMINATE when the task is done. Take a deep breath and think step-by-step\"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "\n",
    "# create a UserProxyAgent instance named \"user_proxy\"\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    code_execution_config={\"work_dir\": \"coding\"},\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "\n",
    "controller = Controller(window_name = \"Mozilla Firefox\")\n",
    "\n",
    "\n",
    "# register the functions\n",
    "user_proxy.register_function(\n",
    "    function_map={\n",
    "        \"take_screenshot\": controller.take_screenshot,\n",
    "        \"move_mouse\": controller.move_mouse,\n",
    "        \"extract_location_from_index\": controller.extract_location_from_index,\n",
    "        \"convert_image_to_base64\": controller.convert_image_to_base64,\n",
    "        \"get_target_UIelement_number\": controller.get_target_UIelement_number,\n",
    "        \"enter_text_at_location\": controller.enter_text_at_location,\n",
    "        \"press_enter\": controller.press_enter,\n",
    "        \"double_click_at_location\": controller.double_click_at_location,\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419e7c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4e077ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# register the functions\n",
    "planner.register_function(\n",
    "    function_map={\n",
    "        \"take_screenshot\": controller.take_screenshot,\n",
    "        \"move_mouse\": controller.move_mouse,\n",
    "        \"extract_location_from_index\": controller.extract_location_from_index,\n",
    "        \"convert_image_to_base64\": controller.convert_image_to_base64,\n",
    "        \"get_target_UIelement_number\": controller.get_target_UIelement_number,\n",
    "        \"enter_text_at_location\": controller.enter_text_at_location,\n",
    "        \"press_enter\": controller.press_enter,\n",
    "        \"double_click_at_location\": controller.double_click_at_location,\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a51d3c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_agents(query):\n",
    "    user_proxy.initiate_chat(\n",
    "        planner,\n",
    "        message=f\"Task is to: {query}. Check if the task is acheived by looking at the window. Don't quit immediately\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76d6affa",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"click on the github icon and click on 'blogs' repository\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17f32575",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to Planner):\n",
      "\n",
      "Task is to: click on the github icon and click on 'blogs' repository. Check if the task is acheived by looking at the window. Don't quit immediately\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPlanner\u001b[0m (to user_proxy):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: take_screenshot *****\u001b[0m\n",
      "Arguments: \n",
      "{}\n",
      "\u001b[32m****************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION take_screenshot...\u001b[0m\n",
      "Taking screenshot....\n",
      "aui_annotate function is called...\n",
      "\u001b[33muser_proxy\u001b[0m (to Planner):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"take_screenshot\" *****\u001b[0m\n",
      "screenshot taken with UI elements numbered at screenshot_annotated.png \n",
      "\u001b[32m************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPlanner\u001b[0m (to user_proxy):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: get_target_UIelement_number *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "\"query\": \"github icon\"\n",
      "}\n",
      "\u001b[32m****************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION get_target_UIelement_number...\u001b[0m\n",
      "GPT resposne is 67\n",
      "\u001b[33muser_proxy\u001b[0m (to Planner):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"get_target_UIelement_number\" *****\u001b[0m\n",
      "67\n",
      "\u001b[32m************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPlanner\u001b[0m (to user_proxy):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: extract_location_from_index *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "\"index\": 67\n",
      "}\n",
      "\u001b[32m****************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION extract_location_from_index...\u001b[0m\n",
      "Extract location function is called...\n",
      "\u001b[33muser_proxy\u001b[0m (to Planner):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"extract_location_from_index\" *****\u001b[0m\n",
      "[1326.5, 1649.0]\n",
      "\u001b[32m************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPlanner\u001b[0m (to user_proxy):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: move_mouse *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "\"x\": 1326.5,\n",
      "\"y\": 1649.0,\n",
      "\"click\": 1\n",
      "}\n",
      "\u001b[32m***********************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION move_mouse...\u001b[0m\n",
      "Moved to 1326.5, 1649.0 and clicked: 1\n",
      "\u001b[33muser_proxy\u001b[0m (to Planner):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"move_mouse\" *****\u001b[0m\n",
      "None\n",
      "\u001b[32m*******************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPlanner\u001b[0m (to user_proxy):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: take_screenshot *****\u001b[0m\n",
      "Arguments: \n",
      "{}\n",
      "\u001b[32m****************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION take_screenshot...\u001b[0m\n",
      "Taking screenshot....\n",
      "aui_annotate function is called...\n",
      "\u001b[33muser_proxy\u001b[0m (to Planner):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"take_screenshot\" *****\u001b[0m\n",
      "screenshot taken with UI elements numbered at screenshot_annotated.png \n",
      "\u001b[32m************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPlanner\u001b[0m (to user_proxy):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: get_target_UIelement_number *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "\"query\": \"'blogs' repository\"\n",
      "}\n",
      "\u001b[32m****************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION get_target_UIelement_number...\u001b[0m\n",
      "GPT resposne is To access the 'blogs' repository, you should select element number 73.\n",
      "\u001b[33muser_proxy\u001b[0m (to Planner):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"get_target_UIelement_number\" *****\u001b[0m\n",
      "73\n",
      "\u001b[32m************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPlanner\u001b[0m (to user_proxy):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: extract_location_from_index *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "\"index\": 73\n",
      "}\n",
      "\u001b[32m****************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION extract_location_from_index...\u001b[0m\n",
      "Extract location function is called...\n",
      "\u001b[33muser_proxy\u001b[0m (to Planner):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"extract_location_from_index\" *****\u001b[0m\n",
      "[336.0, 847.0]\n",
      "\u001b[32m************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPlanner\u001b[0m (to user_proxy):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: move_mouse *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "\"x\": 336.0,\n",
      "\"y\": 847.0,\n",
      "\"click\": 1\n",
      "}\n",
      "\u001b[32m***********************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION move_mouse...\u001b[0m\n",
      "Moved to 336.0, 847.0 and clicked: 1\n",
      "\u001b[33muser_proxy\u001b[0m (to Planner):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"move_mouse\" *****\u001b[0m\n",
      "None\n",
      "\u001b[32m*******************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPlanner\u001b[0m (to user_proxy):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: take_screenshot *****\u001b[0m\n",
      "Arguments: \n",
      "{}\n",
      "\u001b[32m****************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION take_screenshot...\u001b[0m\n",
      "Taking screenshot....\n",
      "aui_annotate function is called...\n",
      "\u001b[33muser_proxy\u001b[0m (to Planner):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"take_screenshot\" *****\u001b[0m\n",
      "screenshot taken with UI elements numbered at screenshot_annotated.png \n",
      "\u001b[32m************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPlanner\u001b[0m (to user_proxy):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start_agents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d282649",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
